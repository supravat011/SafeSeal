# -*- coding: utf-8 -*-
"""Untitled25.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15qFrP-xJHw1f9_z1zZ17zy6aNn9E4P2b
"""

# Install essential libraries for OCR and image handling
!pip install Pillow pytesseract
# Install Tesseract OCR engine (this command is specific to Colab's Linux environment)
!sudo apt install tesseract-ocr

"""Uploading the Certificate Image

"""

from google.colab import files
import io

# This will open a file browser window for you to select and upload your file.
print("Please upload one sample certificate image (JPG or PNG) now.")
uploaded = files.upload()

# Get the name of the uploaded file
# Assuming you upload only one file
uploaded_file_name = list(uploaded.keys())[0]

print(f"\nFile '{uploaded_file_name}' uploaded successfully.")

"""OCR Processing Function

"""

from PIL import Image
import pytesseract
import io

# We need the uploaded_file_name and the 'uploaded' dictionary from the previous cells.
# Run this cell even if the previous one failed, as these variables should still be in memory.

if uploaded_file_name in uploaded:
    # Get the raw bytes of the uploaded file directly
    image_bytes = uploaded[uploaded_file_name]

    try:
        # Open the image using Pillow directly from the byte stream
        img = Image.open(io.BytesIO(image_bytes))

        # Use Tesseract to do the OCR
        # We ensure the image is RGB to avoid potential Tesseract errors with specific modes
        raw_text = pytesseract.image_to_string(img.convert('RGB'))

        print("\n--- Extracted Raw Text (SUCCESS) ---")
        print(raw_text)
        print("------------------------------------")

    except Exception as e:
        # This catches errors if the file is truly not a recognizable image format
        print(f"\n--- ERROR ---")
        print(f"Failed to process image: {e}")
        print("Ensure the uploaded file is a valid JPG or PNG.")
        print("-------------")

else:
    print("Error: The uploaded file variable was not found. Please re-run the file upload block (Block 2).")

# We keep the extracted text in a variable for the next steps
certificate_text = raw_text if 'raw_text' in locals() else ""

"""Data Cleaning and Feature Extraction (Using Regex)"""

import re

# The raw text extracted from the previous block
raw_text = certificate_text

# --- Regex Patterns for Extraction ---

# 1. Student Name: Often appears as a capitalized sequence of words after the course title,
#    or simply as the largest block of capitalized text. This pattern is often tricky,
#    so we'll look for a common naming pattern.
#    A simple heuristic here: find capitalized words followed by a date or course title.
#    Since we see "Vaishnavy Senthilkumar" clearly, we'll try to isolate it.

# A common pattern for names (capitalized words)
name_match = re.search(r'[A-Z][a-z]+\s[A-Z][a-z]+', raw_text)
student_name = name_match.group(0) if name_match else "NOT FOUND"

# 2. Course Title: Usually all caps or capitalized words appearing near "COURSE CERTIFICATE"
#    We will look for text containing "UI/UX" and grab the line.
course_match = re.search(r'Designing User Interfaces and Experiences \(UI/UX\)', raw_text)
course_title = course_match.group(0) if course_match else "NOT FOUND"

# 3. Issue Date: Common date format (Month Day, Year)
date_match = re.search(r'[A-Za-z]+\s\d{1,2},\s\d{4}', raw_text)
issue_date = date_match.group(0) if date_match else "NOT FOUND"

# 4. Institution: Find common institutional names (e.g., IBM)
institution_match = re.search(r'IBM', raw_text)
institution = institution_match.group(0) if institution_match else "NOT FOUND"


# --- Store as a Structured Feature Dictionary ---
content_features = {
    "student_name": student_name,
    "course_title": course_title,
    "issue_date": issue_date,
    "institution": institution,
    "raw_text_length": len(raw_text) # Feature for anomaly detection
}

print("\n--- Extracted Content Features (for AI Model) ---")
for key, value in content_features.items():
    print(f"| {key.ljust(18)} : {value}")
print("--------------------------------------------------")

"""Seal / Logo Match (Computer Vision)"""

# Install TensorFlow and Keras
!pip install tensorflow
import tensorflow as tf
print(f"TensorFlow version: {tf.__version__}")

import os
import shutil

# Define the root data directory
data_dir = 'logo_data'

# Define the institution classes (You will replace these with your actual institution names)
institution_classes = ['NPTEL', 'GOOGLE', 'ANNA UNIVERSITY', 'AMITY UNIVERSITY','COURSERA']

# Create the directory structure
if os.path.exists(data_dir):
    shutil.rmtree(data_dir) # Clear previous data if it exists
os.makedirs(data_dir, exist_ok=True)

print(f"Created root directory: {data_dir}")

# --- SIMULATE Data Collection ---
# In a real scenario, you would manually upload and crop your logo images here.
# For Colab simulation, we just create the folders:
for class_name in institution_classes:
    class_path = os.path.join(data_dir, class_name)
    os.makedirs(class_path, exist_ok=True)

    # NOTE: You must manually upload your actual logo images into these folders
    # when you deploy this on your own machine or in a persistent Colab environment!
    print(f"Created class folder: {class_path}")

print("\nData structure simulation complete. Remember to add actual logo images later!")

"""Setup Data Generators (Loading and Augmenting Data)"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Standard input size for many pre-trained models
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
NUM_CLASSES = len(institution_classes)

# 1. Initialize the Data Generator
# Rescale: Normalizes pixel values (0-255) to (0-1)
# validation_split: Reserves 20% of data for validation during training
datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.1,         # Shear augmentation
    zoom_range=0.1,          # Zoom augmentation
    horizontal_flip=True,    # Flip augmentation
    validation_split=0.2     # 20% validation data
)

# 2. Training Generator
train_generator = datagen.flow_from_directory(
    data_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

# 3. Validation Generator
validation_generator = datagen.flow_from_directory(
    data_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

print(f"\nData generators created for {NUM_CLASSES} classes.")

"""Defining the Transfer Learning Model"""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input
from tensorflow.keras import optimizers

# Configuration from previous step
IMAGE_SIZE = (224, 224)
NUM_CLASSES = 4 # Should match the number of institution classes you defined

# 1. Define the Input Shape
input_tensor = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)) # (224, 224, 3)

# 2. Load MobileNetV2 Base Model
# - weights='imagenet': Uses weights pre-trained on millions of images.
# - include_top=False: Excludes the model's original classification layer.
base_model = MobileNetV2(
    weights='imagenet',
    include_top=False,
    input_tensor=input_tensor
)

# 3. Freeze the Base Layers (Crucial for Transfer Learning)
# This prevents the pre-trained knowledge from being overwritten by our small dataset.
base_model.trainable = False

# 4. Add Custom Top Layers for Classification
# GlobalAveragePooling2D: Flattens the output of the base model efficiently.
# Dense: Standard Neural Network layers for final classification.
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x) # A fully connected layer
predictions = Dense(NUM_CLASSES, activation='softmax')(x) # Output layer for 4 classes

# 5. Create the Final Model
logo_model = Model(inputs=base_model.input, outputs=predictions)

# 6. Compile the Model
# Optimizer: Adam is a good starting choice. Learning rate is set low for fine-tuning.
# Loss: 'categorical_crossentropy' is used for multi-class classification (4 institution logos).
logo_model.compile(
    optimizer=optimizers.Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Print the model structure summary
logo_model.summary()

"""Training the Model (Simulated Block)"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input
from tensorflow.keras import optimizers

# --- Configuration (Ensure these match Block 12) ---
LAYOUT_IMAGE_SIZE = (300, 450)
NUM_LAYOUT_CLASSES = 3

# 1. Define the Input Shape
layout_input = Input(shape=(LAYOUT_IMAGE_SIZE[0], LAYOUT_IMAGE_SIZE[1], 3))

# 2. Load VGG16 Base Model
base_layout_model = VGG16(
    weights='imagenet',
    include_top=False,
    input_tensor=layout_input
)

# 3. Freeze the Base Layers
base_layout_model.trainable = False

# 4. Add Custom Top Layers
x = base_layout_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
layout_predictions = Dense(NUM_LAYOUT_CLASSES, activation='softmax')(x)

# 5. Create and Compile the Final Model
layout_model = Model(inputs=base_layout_model.input, outputs=layout_predictions)

layout_model.compile(
    optimizer=optimizers.Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("\nLayout Model Redefined and Compiled. Ready for Training.")

import os

# --- Configuration ---
layout_data_dir = 'layout_data'
layout_classes = ['IBM_GOOD', 'IBM_BAD', 'OTHERS_LAYOUT']

# 1. Create the root directory
os.makedirs(layout_data_dir, exist_ok=True)

# 2. Create the subdirectories
for class_name in layout_classes:
    class_path = os.path.join(layout_data_dir, class_name)
    os.makedirs(class_path, exist_ok=True)

print(f"Directory structure '{layout_data_dir}/...' is guaranteed to exist.")

"""Rerun Data Generator Block (Confirmation)"""

import os
import shutil
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input
from tensorflow.keras import optimizers

# --- Configuration ---
logo_data_dir = 'logo_data'
# ***CRITICAL: Define your exact Institution Classes here***
# Example: If your filenames are IBM_1.jpg, UCLA_A.jpg, FAKE_3.png
INSTITUTION_CLASSES = ['IBM', 'UCLA', 'FAKE_LOGO', 'OTHERS']
# You need to manually update this list with the exact names you use to prefix your files.

# --- Reorganization ---
# 1. Create subdirectories if they don't exist
for class_name in INSTITUTION_CLASSES:
    class_path = os.path.join(logo_data_dir, class_name)
    os.makedirs(class_path, exist_ok=True)

move_count = 0
# 2. Iterate through files currently loose in logo_data
# This assumes you uploaded files directly to logo_data/
for filename in os.listdir(logo_data_dir):
    source_path = os.path.join(logo_data_dir, filename)

    # Skip directories and the hidden file that Colab often creates
    if os.path.isdir(source_path) or filename.startswith('.'):
        continue

    # 3. Try to match the filename to a class prefix
    target_subdir = None
    for class_name in INSTITUTION_CLASSES:
        if filename.startswith(class_name):
            target_subdir = class_name
            break # Found the folder

    if target_subdir:
        target_path = os.path.join(logo_data_dir, target_subdir, filename)
        shutil.move(source_path, target_path)
        move_count += 1
    # else: If a file doesn't match any prefix, it stays loose (or is ignored).

print(f"Successfully sorted and moved {move_count} logo files into subfolders.")

# --- Data Generator Setup ---
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
NUM_CLASSES = len(INSTITUTION_CLASSES)

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2, rotation_range=15, zoom_range=0.1)

train_generator = datagen.flow_from_directory(
    logo_data_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    logo_data_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# --- Configuration ---
logo_data_dir = 'logo_data'
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
# Since the generator found 9 classes previously, we will trust that the data is correct.

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2, rotation_range=15, zoom_range=0.1)

# Training Generator
train_generator = datagen.flow_from_directory(
    logo_data_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

# Validation Generator
validation_generator = datagen.flow_from_directory(
    logo_data_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

print("\nData generators re-initialized. Check if 'Found 9 classes' is displayed.")

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input
from tensorflow.keras import optimizers
import tensorflow as tf

# --- Configuration (Based on Confirmed Data) ---
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
NUM_CLASSES = 9 # CORRECTED TO MATCH DATA GENERATOR
print(f"FIXED: Model confirmed for {NUM_CLASSES} classes.")

# --- Model Definition (MobileNetV2 Transfer Learning) ---
# 1. Define the input tensor from scratch to avoid the list error
input_tensor = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))

# 2. Load the base model
base_model = MobileNetV2(
    weights='imagenet',
    include_top=False,
    input_tensor=input_tensor
)
base_model.trainable = False

# 3. Add Custom Top Layers for 9 classes
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(NUM_CLASSES, activation='softmax')(x)

logo_model = Model(inputs=base_model.input, outputs=predictions)

# 4. Compile the Model
logo_model.compile(
    optimizer=optimizers.Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# --- Training the Model ---
print("\nStarting Logo Match Model training with 9 classes...")

logo_history = logo_model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // BATCH_SIZE if train_generator.samples > 0 else 1,
    epochs=5, # Run for 5 epochs
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // BATCH_SIZE if validation_generator.samples > 0 else 1
)

print("Logo Match Model training finished.")
logo_model.save('logo_authenticity_model.h5')
print("Model saved as 'logo_authenticity_model.h5'")

"""The Final Integration Logic"""

import tensorflow as tf
import numpy as np
import hashlib
from web3 import Web3
import io

# --- 1. CONFIGURATION (MOCK/EXAMPLE) ---
# NOTE: Replace these mock values with your actual integration code later.
MOCK_BLOCKCHAIN_HASH = "0x1a2b3c4d5e6f7a8b9c0d1e2f3a4b5c6d7e8f9a0b1c2d3e4f5a6b7c8d9e0f1a2b"
# Load the actual trained models (assuming they are saved in the current directory)
logo_model_path = 'logo_authenticity_model.h5'
layout_model_path = 'layout_authenticity_model.h5'

# --- Load Models (MUST be done only once in your full backend application) ---
# NOTE: TensorFlow issues a warning about legacy HDF5 format, which is normal.
try:
    logo_model = tf.keras.models.load_model(logo_model_path)
    layout_model = tf.keras.models.load_model(layout_model_path)
except Exception as e:
    print(f"ERROR LOADING MODELS: {e}. Please ensure both .h5 files are uploaded.")

# --- MOCK INPUT DATA ---
# This simulates the uploaded data from the verifier
# For demonstration, we'll assume the logo model predicts class 0 with 95% confidence (good score)
# And the layout model predicts class 0 with 90% confidence (good score)
MOCK_LOGO_PREDICTION = np.array([[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.95]]) # 9 classes
MOCK_LAYOUT_PREDICTION = np.array([[0.90, 0.05, 0.05]]) # 3 classes

# --- 2. THE VERIFICATION FUNCTION ---
def run_full_verification(uploaded_document_bytes, known_authentic_hash, logo_pred, layout_pred):
    # A. Blockchain Integrity Check
    uploaded_hash_obj = hashlib.sha256()
    uploaded_hash_obj.update(uploaded_document_bytes)
    uploaded_hash = '0x' + uploaded_hash_obj.hexdigest()

    # In a real app, this calls web3.py:
    # hash_match = check_hash_on_ethereum(uploaded_hash)
    hash_match = (uploaded_hash != known_authentic_hash) # MOCK: Simulate a mismatch for demonstration

    if hash_match:
        # B. AI Scoring (Only run if hash check passes)

        # Logo Score: Use the highest probability from the model's output
        logo_score = np.max(logo_pred)

        # Layout Score: Use the confidence of the 'GOOD' layout class (assuming class index 0 is GOOD)
        layout_score = layout_pred[0][0]

        # Derived Signature Score (MVP Strategy)
        signature_score = logo_score * 0.90

        # C. Final Weighted Score Calculation
        W_LOGO = 0.40
        W_LAYOUT = 0.35
        W_SIGNATURE = 0.25

        composite_ai_score = (
            (logo_score * W_LOGO) +
            (layout_score * W_LAYOUT) +
            (signature_score * W_SIGNATURE)
        )

        final_score = round(composite_ai_score * 100, 1)

        return {
            "status": "AUTHENTIC",
            "score": final_score,
            "hash_match": True,
            "logo_score": round(logo_score*100),
            "layout_score": round(layout_score*100)
        }
    else:
        return {
            "status": "FORGED (Hash Mismatch)",
            "score": 0.0,
            "hash_match": False,
            "logo_score": 0,
            "layout_score": 0
        }

# --- 3. RUN MOCK VERIFICATION ---
# Simulate a new document upload (using placeholder bytes)
mock_uploaded_bytes = b"This is a certificate document."

verification_result = run_full_verification(
    mock_uploaded_bytes,
    MOCK_BLOCKCHAIN_HASH,
    MOCK_LOGO_PREDICTION,
    MOCK_LAYOUT_PREDICTION
)

print("\n--- FINAL DECENTRALIZED ACADEMIC CREDENTIAL VERIFICATION REPORT ---")
print(f"1. Blockchain Integrity Check: {'PASS' if verification_result['hash_match'] else 'FAIL'}")
print(f"2. AI Layout Similarity Score: {verification_result['layout_score']}%")
print(f"3. AI Logo Match Score: {verification_result['logo_score']}%")
print(f"4. Derived Signature Score: {round(verification_result['logo_score'] * 0.90)}%")
print("----------------------------------------------------------------")
print(f"üéØ FINAL AUTHENTICITY SCORE: {verification_result['score']}%")
print(f"‚úÖ STATUS: {verification_result['status']}")

# Install the web3.py library for Ethereum interaction
!pip install web3

"""Layout Similarity Scoring"""

import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input
from tensorflow.keras import optimizers
import numpy as np

# --- Configuration for Layout Model ---
LAYOUT_IMAGE_SIZE = (300, 450)
LAYOUT_BATCH_SIZE = 8
layout_data_dir = 'layout_data_unified' # Assuming unified folder structure for simplicity
CLASS_NAME = 'AUTHENTIC'
NUM_LAYOUT_CLASSES = 1 # Simplified model outputting a probability (0 or 1)

# Ensure the required directory structure exists
os.makedirs(os.path.join(layout_data_dir, CLASS_NAME), exist_ok=True)
print(f"Directory structure '{layout_data_dir}/{CLASS_NAME}' is guaranteed.")

# 1. Initialize the Data Generator
layout_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# 2. Training Generator
layout_train_generator = layout_datagen.flow_from_directory(
    layout_data_dir,
    target_size=LAYOUT_IMAGE_SIZE,
    batch_size=LAYOUT_BATCH_SIZE,
    color_mode='rgb',
    class_mode='binary', # Use binary mode for 1 class output
    subset='training'
)

# 3. Validation Generator
layout_validation_generator = layout_datagen.flow_from_directory(
    layout_data_dir,
    target_size=LAYOUT_IMAGE_SIZE,
    batch_size=LAYOUT_BATCH_SIZE,
    color_mode='rgb',
    class_mode='binary',
    subset='validation'
)

# --- Model Definition (VGG16 Feature Extractor) ---
layout_input = Input(shape=(LAYOUT_IMAGE_SIZE[0], LAYOUT_IMAGE_SIZE[1], 3))

base_layout_model = VGG16(
    weights='imagenet',
    include_top=False,
    input_tensor=layout_input
)
base_layout_model.trainable = False

x = base_layout_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
# Final layer uses 1 class with sigmoid activation for binary output (Authentic vs. Anomaly)
layout_predictions = Dense(NUM_LAYOUT_CLASSES, activation='sigmoid')(x)

layout_model = Model(inputs=base_layout_model.input, outputs=layout_predictions)

layout_model.compile(
    optimizer=optimizers.Adam(learning_rate=0.0001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# --- Training the Model ---
print("\nStarting Layout Model training...")
# Check if training is possible
if layout_train_generator.samples == 0:
    print("ERROR: Training failed. Generator found 0 images. Please re-upload layout images to 'layout_data_unified/AUTHENTIC'.")
else:
    layout_history = layout_model.fit(
        layout_train_generator,
        steps_per_epoch=layout_train_generator.samples // LAYOUT_BATCH_SIZE,
        epochs=5,
        validation_data=layout_validation_generator,
        validation_steps=layout_validation_generator.samples // LAYOUT_BATCH_SIZE
    )

    layout_model.save('layout_authenticity_model.h5')
    print("\nLayout Model training finished and saved.")

"""AI Score Integration"""

import tensorflow as tf
import numpy as np
import hashlib
from web3 import Web3 # This should now work!
import os
import io

# --- 1. CONFIGURATION (MOCK/EXAMPLE) ---
# NOTE: Replace these mock values with your actual integration code later.
MOCK_BLOCKCHAIN_HASH = "0x1a2b3c4d5e6f7a8b9c0d1e2f3a4b5c6d7e8f9a0b1c2d3e4f5a6b7c8d9e0f1a2b"
logo_model_path = 'logo_authenticity_model.h5'
layout_model_path = 'layout_authenticity_model.h5'

# --- Load Models ---
try:
    # Use the current directory files saved from Block 22 and Block 25
    logo_model = tf.keras.models.load_model(logo_model_path)
    layout_model = tf.keras.models.load_model(layout_model_path)
    print("Models loaded successfully.")
except Exception as e:
    print(f"CRITICAL ERROR LOADING MODELS: {e}")
    # Fallback to mock predictions if loading fails
    MOCK_LOGO_PREDICTION = np.array([[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.95]])
    MOCK_LAYOUT_PREDICTION = np.array([[0.90]])
    print("Using mock scores for final report simulation.")


# --- MOCK INPUT DATA ---
# This simulates the uploaded data from the verifier
# NOTE: We use mock prediction scores since running inference on the models requires reshaping the uploaded image.
MOCK_LOGO_PREDICTION = np.array([[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.95]]) # 9 classes, 95% confidence on the final class
MOCK_LAYOUT_PREDICTION = np.array([[0.90]]) # 90% confidence on the single 'AUTHENTIC' class

# --- 2. THE VERIFICATION FUNCTION ---
def run_full_verification(uploaded_document_bytes, known_authentic_hash, logo_pred, layout_pred):
    # A. Blockchain Integrity Check
    uploaded_hash_obj = hashlib.sha256()
    uploaded_hash_obj.update(uploaded_document_bytes)
    uploaded_hash = '0x' + uploaded_hash_obj.hexdigest()

    # MOCK Blockchain Check: Simulate a successful match
    hash_match = (uploaded_hash != "0xFAKE_HASH")

    if hash_match:
        # B. AI Scoring

        # Logo Score: Use the highest probability from the model's output (max of 0.95 in mock)
        logo_score = np.max(logo_pred)

        # Layout Score: Use the confidence of the 'AUTHENTIC' layout class (0.90 in mock)
        layout_score = layout_pred[0][0]

        # Derived Signature Score (MVP Strategy: 90% of Logo Score)
        signature_score = logo_score * 0.90

        # C. Final Weighted Score Calculation
        W_LOGO = 0.40
        W_LAYOUT = 0.35
        W_SIGNATURE = 0.25

        composite_ai_score = (
            (logo_score * W_LOGO) +
            (layout_score * W_LAYOUT) +
            (signature_score * W_SIGNATURE)
        )

        final_score = round(composite_ai_score * 100, 1)

        return {
            "status": "AUTHENTIC",
            "score": final_score,
            "hash_match": True,
            "logo_score": round(logo_score*100),
            "layout_score": round(layout_score*100)
        }
    else:
        return {
            "status": "FORGED (Hash Mismatch)",
            "score": 0.0,
            "hash_match": False,
            "logo_score": 0,
            "layout_score": 0
        }

# --- 3. RUN MOCK VERIFICATION ---
# Simulate a new document upload (using placeholder bytes)
mock_uploaded_bytes = b"This is a certificate document."

verification_result = run_full_verification(
    mock_uploaded_bytes,
    MOCK_BLOCKCHAIN_HASH,
    MOCK_LOGO_PREDICTION,
    MOCK_LAYOUT_PREDICTION
)

print("\n--- FINAL DECENTRALIZED ACADEMIC CREDENTIAL VERIFICATION REPORT ---")
print(f"1. Blockchain Integrity Check: {'PASS' if verification_result['hash_match'] else 'FAIL'}")
print(f"2. AI Layout Similarity Score: {verification_result['layout_score']}%")
print(f"3. AI Logo Match Score: {verification_result['logo_score']}%")
print(f"4. Derived Signature Score: {round(verification_result['logo_score'] * 0.90)}%")
print("----------------------------------------------------------------")
print(f"üéØ FINAL AUTHENTICITY SCORE: {verification_result['score']}%")
print(f"‚úÖ STATUS: {verification_result['status']}")

Signature Scoring Logic

import numpy as np

def derive_signature_score_mvp(logo_score, layout_score, threshold=0.80):
    """
    Derives the Signature Authenticity Score based on Logo and Layout scores.

    Logic:
    1. If BOTH scores are high (> threshold): Score is high, with some random variance (90-100%).
    2. If EITHER score is low (< threshold): Score is low, with some random variance (40-70%).
    """
    # Convert input scores (0.0 to 1.0) to boolean conditions
    is_high_integrity = (logo_score >= threshold) and (layout_score >= threshold)

    if is_high_integrity:
        # Case 1: Both high -> Signature Score is high (90% to 100%)
        # np.random.uniform(low, high) generates a random float in the range [low, high)
        signature_score = np.random.uniform(0.90, 1.00)
    else:
        # Case 2: Either or both low -> Signature Score is low (40% to 70%)
        signature_score = np.random.uniform(0.40, 0.70)

    return signature_score

# --- Example of Integration in your main verification flow ---

# Assume these scores were returned from your trained AI models (Layout and Logo)
logo_score_a = 0.95   # High Confidence
layout_score_a = 0.92 # High Confidence

logo_score_b = 0.55   # Low Confidence
layout_score_b = 0.90 # High Confidence (One low score)

logo_score_c = 0.55   # Low Confidence
layout_score_c = 0.45 # Low Confidence (Both low scores)

# Calculate derived scores using the function
signature_score_a = derive_signature_score_mvp(logo_score_a, layout_score_a)
signature_score_b = derive_signature_score_mvp(logo_score_b, layout_score_b)
signature_score_c = derive_signature_score_mvp(logo_score_c, layout_score_c)


print("--- Derived Signature Scores ---")
print(f"Case A (Both High): {round(signature_score_a * 100, 1)}% (Range 90-100%)")
print(f"Case B (One Low):   {round(signature_score_b * 100, 1)}% (Range 40-70%)")
print(f"Case C (Both Low):  {round(signature_score_c * 100, 1)}% (Range 40-70%)")

import tensorflow as tf
import numpy as np
import hashlib
from web3 import Web3
import os
import io

# --- MOCK INPUT DATA (Simulated AI Model Output) ---
# We simulate high scores here to demonstrate a PASS result:
MOCK_LOGO_PREDICTION = np.array([[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.95]])
MOCK_LAYOUT_PREDICTION = np.array([[0.90]])

# --- 1. SIGNATURE SCORING FUNCTION ---
def derive_signature_score_mvp(logo_score, layout_score, threshold=0.80):
    logo_val = np.max(logo_score)
    layout_val = np.max(layout_score)

    is_high_integrity = (logo_val >= threshold) and (layout_val >= threshold)

    if is_high_integrity:
        signature_score = np.random.uniform(0.90, 1.00)
    else:
        signature_score = np.random.uniform(0.40, 0.70)

    return signature_score


# --- 2. THE VERIFICATION FUNCTION ---
def run_full_verification(uploaded_document_bytes, known_authentic_hash, logo_pred, layout_pred):

    # A. Calculate Hash of Uploaded Document (Simulate Verifier Upload)
    uploaded_hash_obj = hashlib.sha256()
    uploaded_hash_obj.update(uploaded_document_bytes)
    uploaded_hash = '0x' + uploaded_hash_obj.hexdigest()

    # B. Blockchain Integrity Check
    hash_match = (uploaded_hash == known_authentic_hash)

    if hash_match:
        # C. AI Scoring (Only run if hash check passes)
        logo_score_val = np.max(logo_pred)
        layout_score_val = np.max(layout_pred)
        signature_score = derive_signature_score_mvp(logo_pred, layout_pred)

        # D. Final Weighted Score Calculation
        W_LOGO = 0.40
        W_LAYOUT = 0.35
        W_SIGNATURE = 0.25

        composite_ai_score = (
            (logo_score_val * W_LOGO) +
            (layout_score_val * W_LAYOUT) +
            (signature_score * W_SIGNATURE)
        )

        final_score = round(composite_ai_score * 100, 1)

        return {
            "status": "AUTHENTIC",
            "score": final_score,
            "hash_match": True,
            "logo_score": round(logo_score_val*100),
            "layout_score": round(layout_score_val*100),
            "signature_score": round(signature_score*100),
            "hash_from_doc": uploaded_hash,
            "hash_from_chain": known_authentic_hash
        }
    else:
        # E. Hard Fail
        return {
            "status": "FORGED (Hash Mismatch)",
            "score": 0.0,
            "hash_match": False,
            "hash_from_doc": uploaded_hash,
            "hash_from_chain": known_authentic_hash
        }

# --- 3. INTERACTIVE RUN ---

# --- Define Example Data for Testing ---
# 1. The document bytes that the verifier has (Simulated uploaded file)
MOCK_UPLOADED_BYTES = b"This is the official certificate document. Student ID: 12345"
# 2. The hash that should be stored on the blockchain for the ORIGINAL document:
ORIGINAL_HASH = '0x' + hashlib.sha256(b"This is the official certificate document. Student ID: 12345").hexdigest()

# --- Interactive Input ---
print("\n--- START INTERACTIVE VERIFICATION ---")
print(f"**ORIGINAL HASH (for testing): {ORIGINAL_HASH}**")
known_authentic_hash = input("Please ENTER the AUTHENTIC HASHCODE from the blockchain: ")

# --- Run Verification ---
verification_result = run_full_verification(
    MOCK_UPLOADED_BYTES,
    known_authentic_hash,
    MOCK_LOGO_PREDICTION,
    MOCK_LAYOUT_PREDICTION
)

# --- 4. FINAL REPORT ---
print("\n--- FINAL DECENTRALIZED ACADEMIC CREDENTIAL VERIFICATION REPORT ---")
print(f"Hash from Uploaded Document: {verification_result['hash_from_doc']}")
print(f"Hash from Blockchain (Input): {verification_result['hash_from_chain']}")
print(f"1. **Blockchain Integrity Check**: {'PASS' if verification_result['hash_match'] else 'FAIL'}")
print("----------------------------------------------------------------")

if verification_result['hash_match']:
    print(f"2. **AI Layout Similarity Score**: {verification_result['layout_score']}%")
    print(f"3. **AI Logo Match Score**: {verification_result['logo_score']}%")
    print(f"4. **Derived Signature Score**: {verification_result['signature_score']}%")
    print("----------------------------------------------------------------")
    print(f"üéØ **OVERALL AUTHENTICITY SCORE:** {verification_result['score']}%")
    print(f"‚úÖ **STATUS:** {verification_result['status']}")
else:
    print(f"üéØ **OVERALL AUTHENTICITY SCORE:** 0.0%")
    print(f"‚ùå **STATUS:** {verification_result['status']}")

import tensorflow as tf
import numpy as np
import hashlib
from web3 import Web3
import os
import io

# --- MOCK INPUT DATA (Simulated AI Model Output) ---
# We simulate high scores here to demonstrate a PASS result:
MOCK_LOGO_PREDICTION = np.array([[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.95]])
MOCK_LAYOUT_PREDICTION = np.array([[0.90]])

# --- 1. SIGNATURE SCORING FUNCTION ---
def derive_signature_score_mvp(logo_score, layout_score, threshold=0.80):
    logo_val = np.max(logo_score)
    layout_val = np.max(layout_score)

    is_high_integrity = (logo_val >= threshold) and (layout_val >= threshold)

    if is_high_integrity:
        signature_score = np.random.uniform(0.90, 1.00)
    else:
        signature_score = np.random.uniform(0.40, 0.70)

    return signature_score


# --- 2. THE VERIFICATION FUNCTION ---
def run_full_verification(uploaded_document_bytes, known_authentic_hash, logo_pred, layout_pred):

    # A. Calculate Hash of Uploaded Document (Simulate Verifier Upload)
    uploaded_hash_obj = hashlib.sha256()
    uploaded_hash_obj.update(uploaded_document_bytes)
    uploaded_hash = '0x' + uploaded_hash_obj.hexdigest()

    # B. Blockchain Integrity Check
    hash_match = (uploaded_hash == known_authentic_hash)

    if hash_match:
        # C. AI Scoring (Only run if hash check passes)
        logo_score_val = np.max(logo_pred)
        layout_score_val = np.max(layout_pred)
        signature_score = derive_signature_score_mvp(logo_pred, layout_pred)

        # D. Final Weighted Score Calculation
        W_LOGO = 0.40
        W_LAYOUT = 0.35
        W_SIGNATURE = 0.25

        composite_ai_score = (
            (logo_score_val * W_LOGO) +
            (layout_score_val * W_LAYOUT) +
            (signature_score * W_SIGNATURE)
        )

        final_score = round(composite_ai_score * 100, 1)

        return {
            "status": "AUTHENTIC",
            "score": final_score,
            "hash_match": True,
            "logo_score": round(logo_score_val*100),
            "layout_score": round(layout_score_val*100),
            "signature_score": round(signature_score*100),
            "hash_from_doc": uploaded_hash,
            "hash_from_chain": known_authentic_hash
        }
    else:
        # E. Hard Fail
        return {
            "status": "FORGED (Hash Mismatch)",
            "score": 0.0,
            "hash_match": False,
            "hash_from_doc": uploaded_hash,
            "hash_from_chain": known_authentic_hash
        }

# --- 3. INTERACTIVE RUN ---

# --- Define Example Data for Testing ---
# 1. The document bytes that the verifier has (Simulated uploaded file)
MOCK_UPLOADED_BYTES = b"This is the official certificate document. Student ID: 12345"
# 2. The hash that should be stored on the blockchain for the ORIGINAL document:
ORIGINAL_HASH = '0x' + hashlib.sha256(MOCK_UPLOADED_BYTES).hexdigest()

# --- Interactive Input ---
print("\n--- START INTERACTIVE VERIFICATION ---")
print(f"**ORIGINAL HASH (Copy this for a PASS): {ORIGINAL_HASH}**")
known_authentic_hash = input("Please ENTER the AUTHENTIC HASHCODE from the blockchain: ")

# --- Run Verification ---
verification_result = run_full_verification(
    MOCK_UPLOADED_BYTES,
    known_authentic_hash,
    MOCK_LOGO_PREDICTION,
    MOCK_LAYOUT_PREDICTION
)

# --- 4. FINAL REPORT ---
print("\n--- FINAL DECENTRALIZED ACADEMIC CREDENTIAL VERIFICATION REPORT ---")
print(f"Hash from Uploaded Document: {verification_result['hash_from_doc']}")
print(f"Hash from Blockchain (Input): {verification_result['hash_from_chain']}")
print(f"1. **Blockchain Integrity Check**: {'PASS' if verification_result['hash_match'] else 'FAIL'}")
print("----------------------------------------------------------------")

if verification_result['hash_match']:
    print(f"2. **AI Layout Similarity Score**: {verification_result['layout_score']}%")
    print(f"3. **AI Logo Match Score**: {verification_result['logo_score']}%")
    print(f"4. **Derived Signature Score**: {verification_result['signature_score']}%")
    print("----------------------------------------------------------------")
    print(f"üéØ **OVERALL AUTHENTICITY SCORE:** {verification_result['score']}%")
    print(f"‚úÖ **STATUS:** {verification_result['status']}")
else:
    print(f"üéØ **OVERALL AUTHENTICITY SCORE:** 0.0%")
    print(f"‚ùå **STATUS:** {verification_result['status']}")